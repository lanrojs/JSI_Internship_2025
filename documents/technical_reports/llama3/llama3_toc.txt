0 Abstract

1 Introduction

2 General Overview

3 Pre-Training
  3.1 Pre-Training Data
    3.1.1 Web Data Curation
    3.1.2 Other Data Sources
    3.1.3 Annealing Data
  3.2 Model Architecture
    3.2.1 Scaling Laws
  3.3 Efficient Pre-Training at Scale
  3.4 Pre-Training Recipe
    3.4.1 Continued Pre-Training for Long Context
    3.4.2 Long Context Pre-Training
    3.4.3 Annealing

4 Post-Training
  4.1 Modeling
    4.1.1 Chat Dialog Format
    4.1.2 Reward Modeling
    4.1.3 Supervised Finetuning (SFT)
    4.1.4 Direct Preference Optimization (DPO)
    4.1.5 Model Sampling and Rejection Sampling
    4.1.6 Iterative Rounds
  4.2 Post-Training Data
    4.2.1 Preference Data
    4.2.2 SFT Data
    4.2.3 Data Quality Control and Cleaning
  4.3 Post-Training for Key Capabilities
    (e.g., reasoning, coding, factuality, multilingual, tools, long context)

5 Results
  5.1 Pre-Trained Language Model
    5.1.1 Standard Benchmarks
    5.1.2 Robustness
    5.1.3 Adversarial Evaluation
    5.1.4 Contamination Analysis
  5.2 Post-Trained Language Model
  5.3 Human Evaluation
  5.4 Safety
    5.4.1 Safety Taxonomy
    5.4.2 Data for Safety Training
    5.4.3 Safety Methodology
    5.4.4 Safety Results
    5.4.5 Tool Use Safety
    5.4.6 Long Context Safety
    5.4.7 Llama Guard 3

6 Efficiency

7 Vision Experiments
  7.1 Image Encoder
  7.2 Image-Language Adapter
  7.3 Video Adapter
  7.4 Training Procedures
  7.5 Evaluation Setup
  7.6 Image Results
  7.7 Video Results

8 Speech
  8.1 Speech Encoder
    8.1.1 Data
    8.1.2 Training Objectives
  8.2 Speech Adapter
    8.2.1 Modeling
    8.2.2 Streaming
  8.3 Speech Generation
    8.3.1 Training
    8.3.2 Inference
  8.4 Speech Understanding Results

9 Related Work
  9.1 Language
  9.2 Multimodality

10 Conclusion

Acknowledgements
Appendix (Contributor List)
